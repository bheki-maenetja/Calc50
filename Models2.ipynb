{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPoKc18XatZqXKQrfG3V+hY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bheki-maenetja/Calc50/blob/master/Models2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Development"
      ],
      "metadata": {
        "id": "qlYlXone2Kks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "WZTaIfhh2RPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_parquet(\"hf://datasets/Jacobvs/PoliticalTweets/formatted_data.parquet\")\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Set stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to clean tweets\n",
        "def clean_tweet(tweet):\n",
        "    tweet = tweet.lower()  # Convert to lowercase\n",
        "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)  # Remove URLs\n",
        "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)  # Remove mentions and hashtags\n",
        "    tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)  # Remove punctuation\n",
        "    tweet_tokens = word_tokenize(tweet)  # Tokenize the tweet\n",
        "    filtered_words = [word for word in tweet_tokens if word not in stop_words]  # Remove stopwords\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Apply cleaning function to tweets\n",
        "df['Cleaned_Tweet'] = df['text'].apply(clean_tweet)\n",
        "\n",
        "# Combine all tweets into a single text\n",
        "republican_tweets = df[df['party'] == 'Republican']['Cleaned_Tweet'].tolist()\n",
        "democratic_tweets = df[df['party'] == 'Democrat']['Cleaned_Tweet'].tolist()\n",
        "\n",
        "# Define the TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(2, 2))  # Use bigrams\n",
        "\n",
        "# Fit the vectorizer on all tweets\n",
        "all_tweets = republican_tweets + democratic_tweets\n",
        "tfidf_vectorizer.fit(all_tweets)\n",
        "\n",
        "# Transform tweets to get TF-IDF scores\n",
        "repub_tfidf = tfidf_vectorizer.transform(republican_tweets)\n",
        "dem_tfidf = tfidf_vectorizer.transform(democratic_tweets)\n",
        "\n",
        "# Calculate average TF-IDF scores for each phrase\n",
        "repub_avg_tfidf = np.array(repub_tfidf.mean(axis=0)).flatten()\n",
        "dem_avg_tfidf = np.array(dem_tfidf.mean(axis=0)).flatten()\n",
        "\n",
        "# Get the feature names (phrases)\n",
        "phrases = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Calculate the difference in average TF-IDF scores\n",
        "tfidf_diff = repub_avg_tfidf - dem_avg_tfidf\n",
        "\n",
        "# Get phrases with the largest differences\n",
        "num_phrases = 50  # Number of top phrases to extract\n",
        "top_repub_phrases = [phrases[i] for i in tfidf_diff.argsort()[-num_phrases:]]\n",
        "top_dem_phrases = [phrases[i] for i in tfidf_diff.argsort()[:num_phrases]]\n",
        "\n",
        "# Build the dictionary\n",
        "partisan_dict = {\n",
        "    \"republican\": top_repub_phrases,\n",
        "    \"democratic\": top_dem_phrases\n",
        "}\n",
        "\n",
        "# # Function to save data to a JSON file\n",
        "# def save_to_json(data, filename):\n",
        "#     with open(filename, \"w\") as outfile:\n",
        "#         json.dump(data, outfile, indent=4)\n",
        "\n",
        "# # Save the dictionary to a JSON file\n",
        "# save_to_json(partisan_dict, \"distinguishing_partisan_dictionary.json\")\n",
        "\n",
        "# print(\"Partisan dictionary saved to distinguishing_partisan_dictionary.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXHqaTKG5HR3",
        "outputId": "d43d4d03-c150-4b6c-d245-56eb8fdd422d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "partisan_dict['democratic']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyGy1Twi5KGQ",
        "outputId": "2b2ffc0d-cdfb-4a79-8b9f-a2d26f8ddbfb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['health care',\n",
              " 'american rescue',\n",
              " 'rescue plan',\n",
              " 'gun violence',\n",
              " 'climate change',\n",
              " 'voting rights',\n",
              " 'child care',\n",
              " 'make sure',\n",
              " 'bipartisan infrastructure',\n",
              " 'climate crisis',\n",
              " 'across country',\n",
              " 'im proud',\n",
              " 'working families',\n",
              " 'get done',\n",
              " 'mental health',\n",
              " 'clean energy',\n",
              " 'right vote',\n",
              " 'social security',\n",
              " 'get vaccinated',\n",
              " 'infrastructure law',\n",
              " 'years ago',\n",
              " 'back better',\n",
              " 'tax credit',\n",
              " 'child tax',\n",
              " 'loved ones',\n",
              " 'john lewis',\n",
              " 'open enrollment',\n",
              " 'build back',\n",
              " 'im glad',\n",
              " 'federal funding',\n",
              " 'inflation reduction',\n",
              " 'reduction act',\n",
              " 'goodpaying jobs',\n",
              " 'health insurance',\n",
              " 'must pass',\n",
              " 'dark money',\n",
              " 'new mexico',\n",
              " 'lower costs',\n",
              " 'ill keep',\n",
              " 'affordable health',\n",
              " 'climate action',\n",
              " 'new hampshire',\n",
              " 'hate crimes',\n",
              " 'town hall',\n",
              " 'im working',\n",
              " 'granite staters',\n",
              " 'keep working',\n",
              " 'paid leave',\n",
              " 'house passed',\n",
              " 'civil rights']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "partisan_dict['republican']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8jw8pvb5MFg",
        "outputId": "56b7ea0b-14ce-4ee3-f0cd-6c0bf2553a0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['white house',\n",
              " 'energy independence',\n",
              " 'petroleum reserve',\n",
              " 'energy production',\n",
              " 'reckless tax',\n",
              " 'illegal aliens',\n",
              " 'took office',\n",
              " 'border policies',\n",
              " 'federal government',\n",
              " 'brave men',\n",
              " 'taxpayer dollars',\n",
              " 'spending bill',\n",
              " 'strategic petroleum',\n",
              " 'democrats want',\n",
              " 'vaccine mandates',\n",
              " 'year high',\n",
              " 'irs agents',\n",
              " 'crisis border',\n",
              " 'biden took',\n",
              " 'open border',\n",
              " 'border security',\n",
              " 'tax spending',\n",
              " 'god bless',\n",
              " 'law enforcement',\n",
              " 'big tech',\n",
              " 'border patrol',\n",
              " 'crisis southern',\n",
              " 'democrats reckless',\n",
              " 'communist party',\n",
              " 'chinese communist',\n",
              " 'gas prices',\n",
              " 'reckless spending',\n",
              " 'communist china',\n",
              " 'spending spree',\n",
              " 'secure border',\n",
              " 'biden administrations',\n",
              " 'vaccine mandate',\n",
              " 'american energy',\n",
              " 'biden admin',\n",
              " 'illegal immigrants',\n",
              " 'american people',\n",
              " 'national security',\n",
              " 'joe bidens',\n",
              " 'men women',\n",
              " 'president bidens',\n",
              " 'border crisis',\n",
              " 'president biden',\n",
              " 'joe biden',\n",
              " 'biden administration',\n",
              " 'southern border']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yYucoQGr6c-s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}